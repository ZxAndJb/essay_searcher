{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-07T12:38:30.285764900Z",
     "start_time": "2025-03-07T12:38:22.634622400Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from utils.prompts import restate_system_message, judge_system_message, response_system_message\n",
    "from utils.data_utils import parse_dict_to_string\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from database import essay_database\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.constants import Send\n",
    "import operator\n",
    "import asyncio\n",
    "from langchain_core.tools import tool\n",
    "import os\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-07T12:38:40.949373600Z",
     "start_time": "2025-03-07T12:38:40.931495700Z"
    }
   },
   "id": "e820b812d346366a",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    user_query: str\n",
    "    restate_query: str\n",
    "    document: List[dict]\n",
    "    cur_check: dict\n",
    "    filtered_document: Annotated[list[dict], operator.add]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-07T12:38:37.619202100Z",
     "start_time": "2025-03-07T12:38:37.614657400Z"
    }
   },
   "id": "7216660184fd9a39",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'url': 'https://www.nowcoder.com/discuss/614470531504435200', 'content': '简介：该项目是由复旦大学发布的针对医疗健康对话式场景而设计的医疗领域大模型与数据集，该模型由DISC-Med-SFT数据集基于Baichuan-13B-Base指令微调得到。'}, {'url': 'https://wqw547243068.github.io/llm_train', 'content': 'L2P 算法是一种较为常用的Prompt selection算法，该算法设计了一种Key-Query的Prompt匹配方法，为每一个Prompt提供一个可学习的索引键k，即 P={(k1,P1),(k2,'}, {'url': 'https://aclanthology.org/2024.ccl-2.pdf', 'content': '... 名为ChatGPT-RetrievalQA的数据集，它基于大语言. 模型响应用户查询生成合成文档来构建。他们利用此数据集和人工生成的数据微调了一系列重. 排序器。在多个'}, {'url': 'https://github.com/Tele-AI/Telechat/blob/master/README.md', 'content': 'TeleChat的分词算法是BBPE算法，该算法是字节级实现的分词算法，任意Unicode字符都可以被表示。 TeleChat 的分词器词表大小为160256，是中英双语的词表。 BBPE算法的实现工具'}, {'url': 'https://arxiv.org/html/2411.07715v1', 'content': '语言模型的目标是通过模拟文本数据的生成概率，实现对自然语言的理解和生成。最初的模型，如n-gram，依赖于统计分析来预测词语序列，但这些模型难以捕捉复杂的'}]\n"
     ]
    }
   ],
   "source": [
    "search = TavilySearchResults(\n",
    "        max_results=5,\n",
    "        search_depth=\"advanced\")\n",
    "for p in search.stream(\"基于双语字典的匹配去筛选SFT数据的算法名称是什么\"):\n",
    "    print(p)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-07T12:46:02.725686900Z",
     "start_time": "2025-03-07T12:46:00.671983400Z"
    }
   },
   "id": "accedb0975dad4c4",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[{'url': 'https://www.nowcoder.com/discuss/614470531504435200',\n  'content': '简介：该项目是由复旦大学发布的针对医疗健康对话式场景而设计的医疗领域大模型与数据集，该模型由DISC-Med-SFT数据集基于Baichuan-13B-Base指令微调得到。'},\n {'url': 'https://wqw547243068.github.io/llm_train',\n  'content': 'L2P 算法是一种较为常用的Prompt selection算法，该算法设计了一种Key-Query的Prompt匹配方法，为每一个Prompt提供一个可学习的索引键k，即 P={(k1,P1),(k2,'},\n {'url': 'https://aclanthology.org/2024.ccl-2.pdf',\n  'content': '... 名为ChatGPT-RetrievalQA的数据集，它基于大语言. 模型响应用户查询生成合成文档来构建。他们利用此数据集和人工生成的数据微调了一系列重. 排序器。在多个'},\n {'url': 'https://github.com/Tele-AI/Telechat/blob/master/README.md',\n  'content': 'TeleChat的分词算法是BBPE算法，该算法是字节级实现的分词算法，任意Unicode字符都可以被表示。 TeleChat 的分词器词表大小为160256，是中英双语的词表。 BBPE算法的实现工具'},\n {'url': 'https://arxiv.org/html/2411.07715v1',\n  'content': '语言模型的目标是通过模拟文本数据的生成概率，实现对自然语言的理解和生成。最初的模型，如n-gram，依赖于统计分析来预测词语序列，但这些模型难以捕捉复杂的'}]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-07T12:45:17.583748900Z",
     "start_time": "2025-03-07T12:45:17.574797500Z"
    }
   },
   "id": "9427e81133037949",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "res = chain.invoke({\"input\": \"他是个骗子\"})\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T07:01:10.300677400Z",
     "start_time": "2025-02-28T07:01:09.610426Z"
    }
   },
   "id": "3150691fb60fe804",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "AIMessage(content=\"He's a fraud.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 31, 'total_tokens': 36, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'qwen-plus', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-bde96db8-86cd-4c97-94a9-57c59f8cde3b-0', usage_metadata={'input_tokens': 31, 'output_tokens': 5, 'total_tokens': 36, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T07:01:12.735702700Z",
     "start_time": "2025-02-28T07:01:12.684774900Z"
    }
   },
   "id": "2af92b47a4b817a9",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"Hello, how are you?\"),\n",
    "    (\"ai\", \"I'm doing well, thanks!\"),\n",
    "    (\"human\", \"That's good to hear.\"),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T07:09:36.640633700Z",
     "start_time": "2025-02-28T07:09:36.638286500Z"
    }
   },
   "id": "ade9af74c34443d2",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "ChatPromptTemplate(input_variables=[], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Hello, how are you?'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"I'm doing well, thanks!\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"That's good to hear.\"), additional_kwargs={})])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T07:09:39.176967500Z",
     "start_time": "2025-02-28T07:09:39.128380300Z"
    }
   },
   "id": "b818ba2a010929e6",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_core.prompts import (\n",
    "    FewShotChatMessagePromptTemplate,\n",
    "    ChatPromptTemplate\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"2+2\", \"output\": \"4\"},\n",
    "    {\"input\": \"2+3\", \"output\": \"5\"},\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "[('human', 'What is {input}?'), \n",
    " ('ai', '{output}')]\n",
    ")\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    examples=examples,\n",
    "    # This is a prompt template used to format each individual example.\n",
    "    example_prompt=example_prompt,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T07:23:50.101194400Z",
     "start_time": "2025-02-28T07:23:50.096643100Z"
    }
   },
   "id": "47d3fc3a4d4c6521",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "FewShotChatMessagePromptTemplate(examples=[{'input': '2+2', 'output': '4'}, {'input': '2+3', 'output': '5'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='What is {input}?'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})]))"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_prompt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T07:23:53.529034Z",
     "start_time": "2025-02-28T07:23:53.457356400Z"
    }
   },
   "id": "a701a95008f7ae2c",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'Say bar'"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt = PromptTemplate.from_template(\"Say {foo}\")\n",
    "prompt.format(foo=\"bar\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-28T07:32:01.386650800Z",
     "start_time": "2025-02-28T07:32:01.382439300Z"
    }
   },
   "id": "aac54cb5a0057364",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c48873f002c040cf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
